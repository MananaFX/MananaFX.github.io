---
title: 情感分析调研
date: 2022-06-23 12:35:17
categories: 人工智能
tags: [大三下,情感分析,调研]

---

# 情感分析调研

## 1 情感分析基础

### 1.1 概念

自然语言处理中的情感分析是分析人类对某个目标对象所蕴含的观点，在业界一般称为<u>观点挖掘</u>（opinion mining），又因主要研究人类通过文字所表达的情感，也称为<u>文本情感分析</u> 。

其主要分析人类对一个目标对象所产生的情感极性、情绪、评价、态度。目标对象包括但不限于商品、服务、组织、个人、事件等等。根据不同场景又有不同任务，例如情绪识别、对话情感分析、情感对话生成、观点分析、观点摘要、主观分析、情感计算、评价分析等等

### 1.2 范围

针对文本的情感分析会分为：`词级别情感分析`、`句子/文档级情感分析`、`目标级情感分析`。其中**词级别和句子级别**的分析对象分别是一个词和整个句子的情感正负向，不区分句子中具体的目标，如实体或属性，相当于**忽略了五要素中的实体和属性这两个要素**。

#### 1.2.1 词级别

即情感词典构建，研究的是如何给词赋予情感信息，如`庆典`对应的情感标签是`正面`。

#### 1.2.2 句子/文档级

研究如何给整个句子或篇章打情感标签，如`今天天气非常好`对应的情感标签是`正面`。

#### 1.2.3 目标级

考虑了具体的目标，该目标可以是`实体`、`某个实体的属性`或`实体加属性`的组合。具体可分为三种

##### 1） Target no aspect based sentiment analysis (TN-ABSA)

TN-ABSA 的分析对象是文本中出现的`实体`的情感正负向，这种情况下没有属性的概念，只有实体。

| 评论                          | Apple Music | 网易云 |      |
| ----------------------------- | :---------: | :----: | ---- |
| Apple Music比网易云干净多了。 |      🙂      |   😣    |      |



##### 2） Target-grounded aspect based sentiment analysis (TG-ABSA)

TG-ABSA 的分析对象是给定某一个实体的情况下该实体给定`属性集合下的各个属性`的情感分析

| 评论                                                         | 材质 | 大小 | 价格 |
| ------------------------------------------------------------ | :--: | :--: | :--: |
| 这款助力带非常好用，牛皮材质经久耐用，大小刚好合适，就是价格偏高。 |  🙂   |  🙂   |  😣   |



##### 3） Target aspect based sentiment analysis (T-ABSA)

T-ABSA 的分析对象是文本中出现的`实体和属性组合`

| 评论                                        | AM外语曲库 | 网易云内地曲库 |
| ------------------------------------------- | :--------: | :------------: |
| Apple Music外语曲库大，但网易云内地曲库大。 |     🙂      |       🙂        |

### 1.3 情感分析要素

情感分析主要有五个要素（`entity/实体，aspect/属性，opinion/观点，holder/观点持有者，time/时间`），其中实体和属性合并称为对象 (target)。而当前研究中一般都不考虑情感分析五要素中的观点持有者和时间，故后文中的讨论都不考虑这两个因素。

![image-20220623153831150](https://mewtiger-1311904225.cos.ap-nanjing.myqcloud.com/post/image-20220623153831150.png)

#### 1.3.1 情感分析五元素

举例：“<u>我觉得陀斯妥耶夫斯写的书很好看</u>”

1. **对象**：表示对哪个对象有观点或情感评价，即「陀思妥耶夫斯基写的书」。
2. **观点**：观点有多种表示法，具体下面会提及，这里暂用极性来说明，即「正面」。
3. **持有者**：即谁表达了该观点，即「我」。如果在文本中没有指明具体持有者，通常需要借助于文本来源信息。记录持有者的意义在于，在后续分析中往往有针对人群观点评估的需要，结合用户画像可以产生很多不同的分析维度，例如分析不同地域的情感差异。
4. **时间**：即观点产生的时间，通常文本中不会显式写出观点产生的时间，也需要借助于文本来源，例如微博的发送时间。观点时间也有利于后续的分析，不同的时间段人群对某类事物的评价也有很大差异。

#### 1.3.2 对象结构化表示

情感对象/评价对象一般用三个元素来表示：`(实体类型，实体，实体方面) - (category, entity, aspect)`。元素之间本身具有层级关系，从左到右概念越来越细化，其中**实体类型**本身也可以有多个层级，而**实体方面**往下也可以继续拆分成多个子方面

**举例**：“<u>《罪与罚》的心理描写很真切</u>”

1. **实体类型**：实体类型为陀思妥耶夫斯基的著作，往上仍有更高的实体类型层级，如`书籍 → 俄国文学 → 小说` 
2. **实体**：《罪与罚》这本书
3. **实体方面**：具体实体的某个属性或子属性，这里为`《罪与罚》—— 心理描写`

#### 1.3.3 情感结构化表示

情感分析要素（对象，观点，持有者，时间）中的**观点**有多种表示方法，可以用三个元素来表示：`(类型，极性/强度，措辞) - (type,orientation/intensity,opinion terms)`。

1. **类型**：可分为理性情感与情绪情感。
   1. **理性情感**一般指的是通用情感，即没有具体情绪类别的情感。如“<u>《罪与罚》的心理描写很真切</u>”
   2. **情绪情感**有具体的情绪标签，并且情绪的定义有时也跟具体业务强相关。如“<u>我喜欢这本书</u>”
2. **极性/强度**：表示对应情感类型的极性或强度，可以用数值表示法（0-10）或类别表示法（正面、负面、中性）。
3. **措辞**：表示具体情感的词组、短语或短句，例如“<u>仰卧起坐效果一般，还容易伤颈椎</u>”，对应的情感词为`一般`。

### 1.4 作用

由于情感分析具有众多的应用场景，如商品评论的分析、舆情分析等等，因此情感分析受到工业界的广泛关注，已成为自然语言处理研究应用落地的重要体现。

另外，情感分析还在社会学、经济学、管理学等领域都显示出重要的研究意义和广泛的应用场景，这些需求对情感分析不断提出了更高的要求，从而推动了情感分析研究的内涵和外延不断拓展和深入。

## 2 方法

情感分析的主要方法分为：基于`情感词典`的情感分析方法、基于`机器学习`的情感分析方法、基于`深度学习`的情感分析方法

### 2.1 情感词典方法

基于词典的文本情感分析技术由于构建的词典往往**只针对某个领域**，对于跨领域情感分析的效果不够好，而且词典中的情感词可能不够丰富，对于短文本和特定领域文本进行情感分析的效果更好。因此，对于长文本来说，更好的解决方法是利用机器学习方法。

#### 2.1.1 人工构建情感字典

人工构建词典是抓取数据之后多次进行人工标注，根据情感表达将词语进行正负向和强弱程度区分。比较典型的中文情感词典是王勇等对微博中的句子构建的极性词典。台湾大学的中文情感极性词典（NTUSD）、知网情感词典 HowNet等。

人工构建词典在扩充词条信息和便利性方面有一定的优势，但是大大增加了人工开销，并且设计的范围有限，不适合跨领域研究。

#### 2.1.2 自动构建情感字典

第一种是**基于知识库的方法**，是对上面的人工构建情感词典进行的拓展，加入名词动词副词，使情感词更加全面。

> 完备的语义知识库, 能够快速构建通用性较强的情感词典, 对词典的精度要求不高的情况下, 这种方法较为实用。中文语义知识库的不足以及领域的限制使得该方法在构建面向单一领域的情感词典中表现不佳。

第二种是**基于语料库的方法**，利用相关领域的大量语料和相关度的计算规则，结合机器学习的方法，自动统计情感词的情感极性，自动构建情感词典。

> 语料库相对于语义知识库而言, 其优点是容易获得且数量充足, 构建的词典在语料所属的领域内表现较好, 但是构建的成本较高, 需要对语料进行预处理, 另外, 所构建的词典的准确率相对不高。

第三种是**知识库和语料库结合**的方法，通过将扩充的情感知识库和特定领域的语料库结合，使构成的情感词典更加丰富。

#### 2.1.3 小结

优点：

1. 能有效反应文本的结构特征，易于理解
2. 在情感词数量充足时分类效果明显

缺点：

1. 没有突破情感词典的限制，要对情感词典不断扩充，使得文本情感判断的准确率不高

### 2.2 基于**传统机器学习**的情感分析方法

#### 2.2.1 朴素贝叶斯

基于朴素贝叶斯的方法是通过计算概率来对文本情感进行分类的，适合增量式训练，特点是`算法简单`

##### 1） 贝叶斯公式

首先计算单个`唯一词`属于各情感类别的概率
$$
P(w_{i}|class) = \frac{freq(w_{i},class)}{N_{class}}
$$

- **P(w<sub>i</sub> | class)** ：词 **w<sub>i</sub>** 属于类别 **class**的概率
- **freq(w<sub>i</sub> | class)** ：词 **w<sub>i</sub>** 在类别为**class**的语料库中出现的频率
- **N<sub>class**</sub>： 类别为**class**的语料库中 **唯一词总数**

###### 例子

有如下四条推文，两条属于积极推文，另外两条属于消极推文

**Positive**: ‘I am happy because I am learning NLP,’ ‘I am happy, not sad.’

**Negative**: ‘I am sad, I am not learning NLP,’ ‘I am sad, not happy.’

- I

  - p( 'I' | positive) = 3/13 = 0.24

  - p( 'I' | negative) = 3/12 = 0.25

- am

  - p( 'am' | positive) = 3/13 = 0.24

  - p( 'am' | negative) = 3/12 = 0.25

通过类似的计算， 可得到所有唯一词属于各类别的概率表

| Word | pos  | neg  |
| :--: | :--: | :--: |
|  i   | 0.24 | 0.25 |
|  am  | 0.24 | 0.25 |
|  \|  |  \|  |  \|  |
|  \|  |  \|  |  \|  |
| not  | 0.08 | 0.17 |
| Sum  |  1   |  1   |

##### 2） 拉普拉斯平滑 (Laplace Smoothing)

如果某个唯一词仅在特定类中出现，那它在其他类中出现的概率就会为0。在之后的朴素贝叶斯中就会导致分母为0情况的出现，因此引入拉普拉斯平滑。

##### 3） 朴素贝叶斯

每个单词对情感产生的影响，可以通过正负两类单词出现的概率之比来计算
$$
\frac{P(w_{i}|pos)}{P(w_{i}|neg)}
$$
而整条推文的情绪就可以使用各唯一词的朴素贝叶斯成绩。同时为了防止数据不平衡以及因此产生的偏差，因此还需要引入`先验因子`。同时为了避免结果过大或过小，对结果取对数。
$$
log(\frac{P(pos)}{P(neg)}
\prod_{i=1}^{m}
\frac{P(w_{i}|pos)}{P(w_{i}|neg)})
$$
若对数似然值大于0，则表明该句子是积极的。

##### 4） 缺点

1. 朴素贝叶斯在贝叶斯公式的基础上做了独立同分布的假设

2. 该方法对输入数据的表达形式很敏感，而且需要计算先验概率，因此会在分类决策方面存在错误率

#### 2.2.2 临近算法（KNN)

KNN算法是常见的分类算法之一，属于有监督学习中的分类算法，全称为K-Nearest Neighbor。

KNN算法的工作方法是将测试集中的每个特征与样本集中的特征进行比较，然后提取前k个最相似的数据标签，比较出现的频率，最后将频率最高的类别作为分类的结果输出。

步骤：

1. 预处理（文本向量化、特征选择）
2. 计算训练集中的点与当前点之间的距离;
3. 按照距离递增次序排序;
4. 选取与当前点距离最小的 k 个点;
5. 确定前 k 个点所在类别的出现频率;
6. 返回前 k个点出现频率最高的类别作为当前点的预测分类。

注意点：

1. **k的选择**：k太小，分类易受噪点影响；k太大，会包含太多其他类别的点
2. **权**：越近的样本越可信，概率越大的样本越可信
3. **距离计算公式**：在文本分类计算相似度中，**余弦**优于**欧式**

#### 2.2.3 支持向量机（SVM）

支持向量机(SVM)是一种基于统计学习理论的机器学习算法。它基于线性分类器的原理首先由Vapnik提出的。SVM可以用于解决线性与非线性样本分类,其核心思想是将低维空间线性不可分的样本点通过核函数映射至高维特征空间中,然后在特征空间中构造出**最优分类超平面**,这时数据在高维空间也可以被超平面分割,从而变得线性可分，并且各个样本与超平面的举例应保持最大。

结果表明，基于Boosting算法的SVM混合情绪分析模型，**性能显著优于单独的SVM模型**。

基于SVM的文本情感分析方法被认为是最好的情感分析方法，该方法泛化错误率低，计算开销不大，而且对于训练样本较小的文本可以得到很好的情感分析效果，对高维数据的处理效果良好，能够得到较低的错误率，但该方法对参数调节和核函数的选择敏感。

#### 2.2.4 小结

优点：

1. 能根据**情感特征的 选取**以及**情感分类器的组合**对文本的情感进行分类

缺点：

1. 不能充分利用`上下文文本`的语境信息，影响分类准确性
2. `数据量大`时完成分类任务的效率和质量低

下表为基于机器学习方法的情感分析的实验结果

![image-20220623210857203](https://mewtiger-1311904225.cos.ap-nanjing.myqcloud.com/post/image-20220623210857203.png)



### 2.3 基于**深度学习**的情感分析方法

#### 2.3.1 单一神经网络的情感分析方法

典型的神经网络学习方法有：`卷积神经网络`（Convolutional Neural Network，CNN）、`递 归 神 经 网 络` （Recurrent Neural Network，RNN）、`长短时记忆`（Long Short-Term Memory，LSTM）网络等。

和使用基于情感词典和传统机器学习的情感分析方法相比，采用神经网络的方法在文本特征学习方面有显著优势，能`主动学习特征`，并对文本中的词语的信息`主动保留`，从而更好地提取到相应词语的语义信息，来有效实现文本的情感分类。

#### 2.3.2 混合（组合、融合）神经网络的情感分析方法

除了对单一神经网络的方法的研究之外，有不少学者在考虑了不同方法的优点后将这些方法进行组合和改进，并将其用于情感分析方面。

#### 2.3.3 引入注意力机制的情感分析

引入注意力机制，能够更好地捕获上下文相关信息，提取语义信息，防止重要信息的丢失，可以有效提高文本情感分类的准确率。现阶段的研究更多的是通过对
预训练模型的微调和改进，从而更有效地提升实验的效果。

#### 2.3.4 使用预训练模型的情感分析

预训练模型是指用数据集已经训练好的模型。通过对预训练模型的微调，可以实现较好的情感分类结果，因此最新的方法大多是使用预训练模型，最新的预训练模型有：ELMo、BERT、XL-NET、ALBERT 等。

#### 2.3.5 小结

**优点**：

1. 能充分利用上下文文本的语境
2. 能主动学习文本特征，保留文本中词语的顺序信息，从而提取到相关词语的语义信息，来实现文本的情感分类。
3. 通过深层网络模型学习数据中的关键信息，来反映数据的特征，从而提升学习的性能。
4. 通过和传统方法相比，使用语言模型预训练的方法充分利用了大规模的单语语料，可以对一词多义进行建模，有效缓解对模型结构的依赖问题。

**缺点**：

1. 基于深度学习的方法需要大量数据支撑，不适合小规模数据集
2. 算法训练时间取决于神经网络的深度和复杂度，一般花费时间较长

## 3 相关任务

## 4 现状、问题和方向

### 4.1 发展与现状

##### 4.1.1 发展

{% timeline Foundations,purple %}

<!-- timeline Wiebe -->

**Private States**, 1994

**Subjectivity Analysis**, 1999

<!-- endtimeline -->

{% endtimeline %}



{% timeline SA on reviews ,purple %}

<!-- timeline Bag of word & Syntactic Rules,Turney 2002 -->

该研究第一次根据评论的情感取向对评论进行分类。其通过列举几个**句法规则**来归纳短语级的`情感挖掘`，并引入**词袋**概念用于`情感标注`。

<!-- endtimeline -->

{% endtimeline %}

{% timeline Sentiment Composition ,purple %}

<!-- timeline Valence Shifters, Polanyi & Zaenen 2006 -->

**情感转移器**即可以改变情感取向的单词和短语，这种移位器有几种类型。最常见的类型是`否定词`。但并不是情感转移器的每一次出现都会改变情感取向，例如，“**不仅……而且**”。

<!-- endtimeline -->

<!-- timeline Opinion Summarization, Hu & Liu 2004 -->

**观点摘要**是观点挖掘`结构化`的关键任务，其目标是将一群人的多个观点进行结构化提取和展示，即观点摘要是一群观点的结构化表示。由于结构化需要比较细的粒度，一般用于 `Aspect` （方面）粒度的摘要。

<!-- endtimeline -->

{% endtimeline %}



{% timeline Lexicons for SA ,purple %}

<!-- timeline Senti/WordNet, ESuli 2006 -->

**Senti/WordNet**是一个有名的情感词典，构筑于Wordnet。 在该词典中，每一个`同义词集合`依据他们的词义，分别被赋予了肯定、否定和客观的分数。

<!-- endtimeline -->

<!-- timeline SO-CAL, Taboada 2001 -->

**SO-CAL**是一个基于词汇的`情绪计算器`。 在其内部的词典中，每个词与它的语义情感相关联(极性和强度)。 它的优势在于能够理解`情感转移器`，如强化、减弱以及否定。 

<!-- endtimeline -->

{% endtimeline %}



{% timeline Sentiment-specific Word Embeddings,purple %}

<!-- timeline Sentiment Loss, Tang et al 2014 -->

这项工作提供了为情感分析提供了量身定制的词汇表征，以将`情感信息`融入了`学习损失`中来解释情感规律。

<!-- endtimeline -->

{% endtimeline %}



{% timeline Deep Learning,purple %}

<!-- timeline RNTN, Socher et al 2013 -->

**递归神经张量网络**是深度学习时代的初始模型之一，它可以通过对句子中短语的情感的影响及范围进行建模，来确定句子的情感。

<!-- endtimeline -->

<!-- timeline CNN, Kim et al 2014 -->

其提出的**卷积神经网络**具有优越的`特征提取`和`分类能力`，因此可以尝试把文本视为一维图像，用CNN来对文本进行分类。

<!-- endtimeline -->

{% endtimeline %}



{% timeline Contextual Language Models,purple %}

<!-- timeline ULMFit, Howard & Ruder 2018 -->

ULMFiT用于实现像CV领域的迁移学习，并可以用于任意NLP任务，其共分为3个阶段，首先是语言模型的预训练、然后是语言模型的finetune、最后是分类任务的finetune

`finetune`即**微调**将冻结预训练模型的部分层（通常是靠近输入的多数层），训练剩下的层（通常是靠近输出的部分层）。

在语言模型的finetune中，作者根据经验对不同层使用了`不同的学习率`，以提高训练的效率，并使用了倾斜的`三角学习率`，使参数快速收敛到合适区域后再缓慢调整。

在分类任务的finetune中，`逐层解冻`前面的层，以防止**灾难性遗忘**（丢失预训练中学习到的内容），并单独训练`两个方向`的语言模型，最后的预测结果为两个模型的融合。

<!-- endtimeline -->

<!-- timeline BERT, Devlin 2019 -->

BERT是一个预训练的语言表征模型。它采用新的**masked language model（MLM）**，以致能生成**深度的双向**语言表征。其在11种不同NLP测试中创出SOTA表现，是NLP发展史上里程碑式的模型成就。

Masked LM

1. 在在每一个训练序列中以15%的概率随机地选中某个token位置用于预测
   1. 80%的概率下，用`[MASK]`标记替换该token
   2. 10%的概率下，用`随机单词`替换该token
   3. 10%的概率下，该token`保持不变`
2. 预测出原来的token并计算loss
3. 利用这种高度不确定的情况，可以倒逼模型快速学习该token的`上下文语义`，令到BERT不再只对[MASK]敏感，而是对所有的token都敏感，以致能抽取出任何token的表征信息。

<!-- endtimeline -->

{% endtimeline %}

#### 4.1.2 现状

如今的NLP领域已经被`预训练模型`占领了，目前大多情感分析任务也都是在预训练模型的基础上进行的。下图为在IMDB、SST-2/5、Semeval数据集上不同方法的准确率。SOTA（表现最好的模型）无一例外都是基于预训练模型的。![image-20220624190047278](https://mewtiger-1311904225.cos.ap-nanjing.myqcloud.com/post/image-20220624190047278.png)

由此可以观察到，每当NLP领域出现一种范式转换后，会先将该范式应用于情感分析，再根据情感分析的特点去改善这种模式。将**情感本身特点融入到语言模型中**也正是目前的一个研究热点，最近的很多工作也确实在朝着这个方向努力。

### 4.2 问题和挑战

#### 4.2.1 领域依赖

是指文本情感分析的模型对某一领域的文本数据非常有效，但是将其应用于其他领域的时候，会使得分类模型的性能严重下降。

#### 4.2.2 情感语义理解

由于自然语言情感表达的复杂性，使得计算机能够精确理解文本中的情感语义，就必须借助自然语言理解技术，难度较大。

（3）**特征提取**

现有的文本情感分析使用的提取特征的方法能达到的精度还有限，如何有效地表达语句作者情感的特征，是尚待研究的。

（4）**样本标注**

虽然针对产品评论的情感分析，可以通过用户对该产品的打分来进行标注，但是绝大部分情感分析领域，有监督的机器学习情感分析方法，无法在训练阶段或者精确的标注样本，而人工进行标注的话，则非常困难，因此样本标注也是一个待解决的挑战。

### 4.3 方向

（1）通过对比不同的研究方法可以发现，现有的对于情感分析的研究方法多基于单一领域，如社交网络媒体平台weibo、酒店评论等，在个性化推荐中如何将多个领域的内容结合，进行情感分类，实现更好的推荐效果，并实现在提高模型的泛用性能，都是未来值得研究和探索的工作方向。

（2）大部分对于情感分析的研究多用于显式的文本情感分类问题，采用含有明显情感词的数据集，而对于某些隐式词的检测和分类效果不佳。现阶段对于隐式情感分析的研究还处于起步阶段，不是很充分，未来可以通过构建隐式情感词词典，或者通过使用更好的深度学习方法来更深层次地提取语义相关信息来实现更好的情感分类效果。

（3）对于复杂语句的情感分析研究需要进一步完善，当带有情感倾向的网络用语、歇后语、成语等越来越频繁地出现，尤其在文本中含有反讽或隐喻类的词时，情感极性的检测就会存在难度，这也需要进一步研究。

（4）多模态情感分析也是近来的研究热点，如何将多个模态中的情感信息进行提取和融合，是大家主要研究的方向，当多个模态中的情感表达不一致时，该如何权重不同模态中的情感信息也是需要考虑的；以及是否能考虑外部语义信息，这对情感分析的准确性是否有帮助，也是需要有大量的研究。

（5）在情感分析的子任务中，也能发现大多研究是基于简单二分类情感分析，实现多分类，更加细粒度的情感分析也是将来的研究热点。

（6）预训练模型是现阶段的研究热点，它能有效解决传统方法中存在的问题，如不能并行化计算的限制等，还能有效捕获词语之间的相互关系，并且通过微调就能在下游任务中实现较好的效果，但也会存在模型参数量大，训练时间较长的问题。如何在模型的参数量小，有效缩短训练时间的前提下，达到好的分类效果，也会是值得研究的方向。

## 参考资料

**[1]** 王婷,杨文忠.文本情感分析方法研究综述[J].计算机工程与应用,2021,57(12):11-24.

**[2]** 洪巍,李敏.文本情感分析方法研究综述[J].计算机工程与科学,2019,41(04):750-757.

**[3]** 全面解读文本情感分析, https://zhuanlan.zhihu.com/p/270399396 

**[4]** 华为云细粒度文本情感分析及应用 , https://blog.csdn.net/qq_27590277/article/details/114465660

**[5]** 一文看懂情感分析技术应用与趋势 , https://zhuanlan.zhihu.com/p/354306620

**[6]** 情感分析的基础知识介绍 , https://zhuanlan.zhihu.com/p/391712395

**[7]** 文本情感分析方法研究小结, https://zhuanlan.zhihu.com/p/106588589

**[8]** Sentiment Analysis of a Tweet With Naive Bayes, https://towardsdatascience.com/sentiment-analysis-of-a-tweet-with-naive-bayes-ff9bdb2949c7

**[9]** Poria S ,  Hazarika D ,  Majumder N , et al. Beneath the Tip of the Iceberg: Current Challenges and New Directions in Sentiment Analysis Research[J].  2020.
